# Advanced Format Specification

**Document Type**: `advanced.md`
**Purpose**: Edge cases, performance considerations, and complex scenarios
**Target**: Consumption graph output
**Generated By**: ContentGenerator tool

## Purpose

Advanced documents provide in-depth coverage of complex scenarios, performance optimization, edge cases, and advanced usage patterns. They target experienced developers and enable LLMs to handle sophisticated questions and implementation challenges that go beyond basic usage.

## Structure Requirements

### Header
```markdown
# [Topic Name] Advanced

Edge cases, performance considerations, and complex scenarios for [topic name].
```

### Core Sections

1. **Performance Optimization** (Required)
   - Performance characteristics and benchmarks
   - Optimization techniques and best practices
   - Memory usage considerations
   - Scalability factors

2. **Edge Cases and Limitations** (Required)
   - Boundary conditions and unusual scenarios
   - Known limitations and workarounds
   - Platform-specific considerations
   - Version-specific behavior differences

3. **Advanced Usage Patterns** (Required)
   - Complex implementation scenarios
   - Expert-level techniques
   - Custom extensions and modifications
   - Integration with advanced .NET features

4. **Troubleshooting Complex Issues** (Optional)
   - Advanced diagnostic techniques
   - Performance profiling approaches
   - Complex error scenarios and resolution

## Content Guidelines

### Technical Depth
- **Expert-Level**: Assumes strong .NET knowledge
- **Detailed**: Provides comprehensive coverage of complex topics
- **Authoritative**: Based on official documentation and expert sources
- **Current**: Reflects latest .NET capabilities and best practices

### Writing Style
- **Detailed Explanations**: More thorough than other document types
- **Technical Precision**: Use exact terminology and specifications
- **Context-Rich**: Explain why advanced techniques matter
- **Evidence-Based**: Include performance data and benchmarks when relevant

### Code Examples
- **Complex Scenarios**: Show sophisticated implementation patterns
- **Production-Ready**: Examples should reflect real-world complexity
- **Optimized**: Demonstrate performance-conscious implementations
- **Complete**: Include necessary error handling and edge case management

## Content Organization

### Advanced Topic Pattern
```markdown
### [Advanced Topic Name]

**Context**: When and why this advanced technique applies
**Implementation**: Detailed implementation approach
**Performance Impact**: Quantified performance characteristics
**Trade-offs**: Benefits and costs of this approach
**Alternatives**: Other approaches and when to use them
```

### Performance Section Structure
- **Baseline**: Establish performance expectations
- **Optimization**: Specific improvement techniques
- **Measurement**: How to validate improvements
- **Trade-offs**: What optimization costs in complexity or functionality

## Quality Standards

### Similarity Requirements
- Must align with golden reference advanced guidance
- Should build upon concepts in other document types
- Advanced techniques must be technically sound and current

### Content Validation
- All performance claims must be verifiable
- Code examples must be production-quality
- Edge cases must be accurately described
- Optimization techniques must be proven effective

## Example Structure

```markdown
# File I/O Advanced

Edge cases, performance considerations, and complex scenarios for file operations.

## Performance Optimization

### Memory-Efficient Large File Processing
When processing files larger than available memory, streaming approaches prevent OutOfMemoryException:

```csharp
public async Task ProcessLargeFileAsync(string inputPath, string outputPath)
{
    const int bufferSize = 1024 * 1024; // 1MB buffer

    using var input = new FileStream(inputPath, FileMode.Open, FileAccess.Read, FileShare.Read, bufferSize);
    using var output = new FileStream(outputPath, FileMode.Create, FileAccess.Write, FileShare.None, bufferSize);

    var buffer = new byte[bufferSize];
    int bytesRead;

    while ((bytesRead = await input.ReadAsync(buffer, 0, buffer.Length)) > 0)
    {
        // Process buffer content
        ProcessBuffer(buffer.AsSpan(0, bytesRead));
        await output.WriteAsync(buffer, 0, bytesRead);
    }
}
```

**Performance Impact**: Reduces memory usage from file size to buffer size (1MB vs potentially GBs)
**Trade-offs**: More complex code, sequential processing only

### Asynchronous Parallel File Processing
For CPU-intensive file operations, parallel processing improves throughput:

```csharp
public async Task ProcessFilesParallelAsync(IEnumerable<string> filePaths)
{
    var semaphore = new SemaphoreSlim(Environment.ProcessorCount);
    var tasks = filePaths.Select(async path =>
    {
        await semaphore.WaitAsync();
        try
        {
            return await ProcessSingleFileAsync(path);
        }
        finally
        {
            semaphore.Release();
        }
    });

    var results = await Task.WhenAll(tasks);
}
```

**Performance Impact**: Near-linear scaling with CPU core count for CPU-bound operations
**Trade-offs**: Higher memory usage, resource contention possible

## Edge Cases and Limitations

### File System Path Limitations
Different platforms have varying path length and character restrictions:

```csharp
public static class PathValidator
{
    public static bool IsValidPath(string path)
    {
        if (string.IsNullOrWhiteSpace(path))
            return false;

        // Windows: 260 character limit for full path in legacy mode
        if (OperatingSystem.IsWindows() && path.Length > 260)
        {
            // Check if long path support is enabled
            if (!IsLongPathSupportEnabled())
                return false;
        }

        // Check for invalid characters
        var invalidChars = Path.GetInvalidPathChars();
        if (path.Any(c => invalidChars.Contains(c)))
            return false;

        return true;
    }

    private static bool IsLongPathSupportEnabled()
    {
        // Check registry or use try-catch approach
        try
        {
            Directory.GetDirectories(new string('a', 300));
            return true;
        }
        catch (PathTooLongException)
        {
            return false;
        }
    }
}
```

### Concurrent File Access Patterns
Managing concurrent access requires careful consideration of file sharing modes:

```csharp
public class ConcurrentFileManager
{
    private readonly ConcurrentDictionary<string, SemaphoreSlim> _fileLocks = new();

    public async Task<T> AccessFileExclusivelyAsync<T>(string path, Func<FileStream, Task<T>> operation)
    {
        var semaphore = _fileLocks.GetOrAdd(path, _ => new SemaphoreSlim(1, 1));

        await semaphore.WaitAsync();
        try
        {
            using var stream = new FileStream(path, FileMode.OpenOrCreate, FileAccess.ReadWrite, FileShare.None);
            return await operation(stream);
        }
        finally
        {
            semaphore.Release();

            // Clean up unused semaphores
            if (semaphore.CurrentCount == 1)
            {
                _fileLocks.TryRemove(path, out _);
            }
        }
    }
}
```

## Advanced Usage Patterns

### Custom Stream Implementations
For specialized scenarios, custom stream implementations provide fine-grained control:

```csharp
public class EncryptedFileStream : Stream
{
    private readonly Stream _baseStream;
    private readonly ICryptoTransform _encryptor;
    private readonly ICryptoTransform _decryptor;

    public EncryptedFileStream(string path, FileMode mode, byte[] key)
    {
        _baseStream = new FileStream(path, mode);

        using var aes = Aes.Create();
        aes.Key = key;
        aes.IV = new byte[16]; // In production, use proper IV handling

        _encryptor = aes.CreateEncryptor();
        _decryptor = aes.CreateDecryptor();
    }

    public override void Write(byte[] buffer, int offset, int count)
    {
        var encryptedBuffer = _encryptor.TransformFinalBlock(buffer, offset, count);
        _baseStream.Write(encryptedBuffer, 0, encryptedBuffer.Length);
    }

    public override int Read(byte[] buffer, int offset, int count)
    {
        var tempBuffer = new byte[count];
        var bytesRead = _baseStream.Read(tempBuffer, 0, count);

        if (bytesRead > 0)
        {
            var decryptedData = _decryptor.TransformFinalBlock(tempBuffer, 0, bytesRead);
            Array.Copy(decryptedData, 0, buffer, offset, decryptedData.Length);
            return decryptedData.Length;
        }

        return 0;
    }

    // Implementation of other Stream abstract members...
}
```

### Memory-Mapped File Operations
For large files requiring random access, memory-mapped files provide optimal performance:

```csharp
public class MemoryMappedFileProcessor : IDisposable
{
    private readonly MemoryMappedFile _mmf;
    private readonly MemoryMappedViewAccessor _accessor;

    public MemoryMappedFileProcessor(string filePath)
    {
        var fileInfo = new FileInfo(filePath);
        _mmf = MemoryMappedFile.CreateFromFile(filePath, FileMode.Open, "mmf", fileInfo.Length);
        _accessor = _mmf.CreateViewAccessor(0, fileInfo.Length);
    }

    public unsafe void ProcessDataInParallel()
    {
        var dataLength = _accessor.Capacity;
        var chunkSize = dataLength / Environment.ProcessorCount;

        Parallel.For(0, Environment.ProcessorCount, i =>
        {
            var start = i * chunkSize;
            var end = (i == Environment.ProcessorCount - 1) ? dataLength : (i + 1) * chunkSize;

            for (long pos = start; pos < end; pos += sizeof(int))
            {
                var value = _accessor.ReadInt32(pos);
                // Process value
                _accessor.Write(pos, ProcessValue(value));
            }
        });
    }

    private int ProcessValue(int value) => value * 2; // Example processing

    public void Dispose()
    {
        _accessor?.Dispose();
        _mmf?.Dispose();
    }
}
```

## Troubleshooting Complex Issues

### Performance Profiling File Operations
Use ETW events and performance counters for detailed analysis:

```csharp
public class FileOperationProfiler
{
    private static readonly ActivitySource ActivitySource = new("FileOperations");

    public async Task<T> ProfiledOperationAsync<T>(string operationName, Func<Task<T>> operation)
    {
        using var activity = ActivitySource.StartActivity(operationName);

        var stopwatch = Stopwatch.StartNew();
        try
        {
            var result = await operation();

            activity?.SetTag("success", true);
            activity?.SetTag("duration_ms", stopwatch.ElapsedMilliseconds);

            return result;
        }
        catch (Exception ex)
        {
            activity?.SetTag("success", false);
            activity?.SetTag("error", ex.GetType().Name);
            activity?.SetTag("duration_ms", stopwatch.ElapsedMilliseconds);

            throw;
        }
    }
}

// Usage
var profiler = new FileOperationProfiler();
var content = await profiler.ProfiledOperationAsync("ReadLargeFile",
    () => File.ReadAllTextAsync(largePath));
```
```

## Generation Notes

When ContentGenerator creates advanced documents:

1. **Depth Analysis**: Identify complex scenarios and edge cases from golden reference
2. **Performance Focus**: Include quantified performance characteristics when possible
3. **Expert Targeting**: Assume advanced .NET knowledge and experience
4. **Production Readiness**: Show enterprise-grade implementation patterns
5. **Current Best Practices**: Reflect latest .NET capabilities and recommendations

Advanced documents should enable LLMs to handle sophisticated technical questions and provide expert-level guidance for complex scenarios.