# Embedding and Similarity Analysis

This document consolidates insights and practices for semantic embedding and similarity analysis within the .NET LLM documentation system.

## Overview

The embedding and similarity system provides the semantic foundation for content validation, relationship discovery, and quality assurance across both source and consumption graphs. It uses the mxbai-embed-large embedding model via Ollama for consistent, high-quality analysis.

## File Organization Structure

The documentation system uses a clear separation between core content and embedding artifacts:

```text
docs/category/topic/
├── topic-spec.md              # Core content files
├── golden-reference.md
├── qa-pairs.md
├── validation.md              # Optional
├── index.json
├── _similarities/             # Cross-topic relationship artifacts
│   ├── cli.md
│   ├── csharp.md
│   ├── dotnet.md
│   ├── extensions.md
│   └── libraries.md
└── _embeddings/               # Processing artifacts
    ├── _embedding.txt
    ├── topic-spec.md._embedding.txt
    ├── topic-spec.md._tokencount.txt
    ├── golden-reference.md._embedding.txt
    ├── golden-reference.md._tokencount.txt
    ├── qa-pairs.md._embedding.txt
    └── qa-pairs.md._tokencount.txt
```

## Embedding Artifacts

### Core Embedding Files

| File Pattern | Purpose | Format | Generated By |
|--------------|---------|--------|--------------|
| `*._embedding.txt` | Human-readable embedding metadata | Text | EmbeddingTool |
| `*._tokencount.txt` | Token count analysis | Text | EmbeddingTool |
| `_embedding.txt` | Aggregate embedding information | Text | EmbeddingTool |

### Similarity Analysis Files

| File Name | Purpose | Format | Generated By |
|-----------|---------|--------|--------------|
| `cli.md` | Cross-category similarity to CLI topics | Text | EmbeddingTool |
| `csharp.md` | Cross-category similarity to C# topics | Text | EmbeddingTool |
| `dotnet.md` | Cross-category similarity to .NET platform topics | Text | EmbeddingTool |
| `extensions.md` | Cross-category similarity to Extensions topics | Text | EmbeddingTool |
| `libraries.md` | Cross-category similarity to Libraries topics | Text | EmbeddingTool |

## Quality Assurance Through Similarity

### Similarity Thresholds

The system uses similarity scores to validate content quality against golden references:

- **Target**: >0.7 similarity to golden-reference.md
- **Warning**: 0.5-0.7 similarity score
- **Error**: <0.5 similarity score

### Validation Process

1. **Content Generation**: Generated content is compared against `golden-reference.md`
2. **Similarity Scoring**: EmbeddingTool calculates similarity using mxbai-embed-large model
3. **Quality Gates**: Content must meet similarity thresholds to pass validation
4. **Relationship Mapping**: Cross-topic similarities inform content connections

## Complexity Scoring Analysis

### The Calibration Challenge

LLM-based complexity scoring requires careful calibration to produce meaningful distributions across the .NET ecosystem. Initial analysis revealed systematic inflation where all topics clustered in the 0.6-0.9 range instead of utilizing the full 0.0-1.0 scale.

### Expected vs. Actual Distribution

**Target Distribution:**
- **Simple topics** (basic syntax, syntactic sugar): 0.1-0.3
- **Intermediate topics** (standard patterns): 0.4-0.6
- **Advanced topics** (complex scenarios): 0.7-0.9
- **Expert topics** (internals, edge cases): 0.9-1.0

**Observed Issues:**
- Collection expressions (intentionally simple): scored 0.6
- File-based apps (basic scripting): scored 0.6
- System.Text.Json (standard library): scored 0.6
- Build & Compilation: scored 0.8
- Native AOT, C# 14 features: scored 0.9

### .NET Complexity Context

Complexity scoring must be calibrated relative to the .NET ecosystem, not absolute programming complexity:

**Simple (0.1-0.3):**
- Collection expressions: `[1, 2, 3]`
- Basic properties: `public string Name { get; set; }`
- Console output: `Console.WriteLine("Hello")`

**Intermediate (0.4-0.6):**
- LINQ basics: `.Where(x => x.IsActive)`
- Simple async: `await GetDataAsync()`
- Basic generics: `List<T>`

**Advanced (0.7-0.9):**
- Complex generics with constraints
- Reflection and metaprogramming
- Unsafe code and pointers
- Advanced async patterns

**Expert (0.9-1.0):**
- Compiler services
- Runtime manipulation
- Low-level performance optimization

### Calibration Approach

To achieve proper complexity distribution:

1. **Baseline Testing**: Use collection expressions as a simple topic baseline (~0.2-0.3)
2. **Context Anchoring**: Provide explicit .NET complexity examples in scoring prompts
3. **Validation**: Ensure score distribution matches expected .NET complexity spectrum
4. **Consistency**: Verify similar complexity topics receive similar scores

## File Lifecycle and Management

### Core Content Lifecycle
- Created manually or through content generation tools
- Versioned in git repository
- Subject to format validation and linting
- Updated through normal development workflow

### Embedding Artifacts
- Generated automatically by EmbeddingTool
- Not versioned in git (should be in .gitignore)
- Regenerated as needed from core content
- Organized in dedicated directories (`_embeddings`, `_similarities`)

### Processing Pipeline Phases

**Phase 1: Content Generation**
- Input: topic-spec.md, repos.md, category context
- Output: golden-reference.md, qa-pairs.md, validation.md
- Focus: Creating high-quality human-readable content

**Phase 2: Embedding and Analysis**
- Input: All markdown content from Phase 1
- Output: `_embeddings/` and `_similarities/` artifacts
- Focus: Creating machine-readable representations for similarity and retrieval

## Model Strategy

### Embedding Model: mxbai-embed-large
- **Rationale**: High-performance embeddings with superior quality compared to nomic-embed-text
- **Usage**: Both source and consumption graphs
- **Infrastructure**: Local Ollama server (very efficient/effective with 16GB VRAM capacity)
- **Consistency**: Same model used across all embedding operations for comparable results

### Token Counting Strategy
- **Source Graph**: mxbai-embed-large embedding model for consistency and low cost
- **Consumption Graph**: Same model used for generation to ensure budget accuracy
- **Benefit**: Generation targets and counting validation perfectly aligned

## Best Practices

### File Management
- Keep core content in main directory
- Use underscore-prefixed directories for artifacts (`_embeddings`, `_similarities`)
- Never manually edit processing artifacts
- Regular cleanup of stale processing artifacts

### Quality Validation
- All generated content must meet similarity thresholds
- Use embeddings for content relationship discovery
- Validate complexity scores against .NET ecosystem context
- Monitor similarity distributions for calibration drift

### Processing Efficiency
- Batch embedding operations when possible
- Cache embeddings to avoid recomputation
- Use similarity scores for content filtering and recommendation
- Leverage relationship analysis for cross-topic connections

## Integration with Architecture

The embedding and similarity system integrates with the broader architecture:

- **Index Tool**: Uses similarity data for relationship mapping in HAL+JSON structures
- **ContentGenerator**: Validates output against golden reference similarity thresholds
- **CopyGraph Tool**: Preserves embedding relationships when copying to consumption graph
- **LlmDocTester**: Uses embeddings for content-assisted vs baseline performance comparison

This embedding foundation enables sophisticated semantic analysis, quality assurance, and content discovery across the entire .NET LLM documentation system.